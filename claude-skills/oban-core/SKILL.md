---
name: oban-core
description: Core Oban documentation (fallback reference - use ash-oban skill for async work). Do not use directly; this provides underlying Oban library details when ash-oban doesn't cover something.
---

# Oban-Core Skill

Comprehensive assistance with oban-core development, generated from official documentation.

## When to Use This Skill

This skill should be triggered when:
- Working with oban-core
- Asking about oban-core features or APIs
- Implementing oban-core solutions
- Debugging oban-core code
- Learning oban-core best practices

## Quick Reference

### Common Patterns

**Pattern 1:** __using__(opts \\ []) (macro) Creates a facade for Oban functions and automates fetching configuration from the application environment.Facade modules support configuration via the application environment under an OTP application key that you specify with :otp_app. For example, to define a facade:defmodule MyApp.Oban do use Oban, otp_app: :my_app endThen, you can configure the facade with:config :my_app, MyApp.Oban, repo: MyApp.RepoThen you can include MyApp.Oban in your application's supervision tree without passing extra options:defmodule MyApp.Application do use Application def start(_type, _args) do children = [ MyApp.Repo, MyApp.Oban ] opts = [strategy: :one_for_one, name: MyApp.Supervisor] Supervisor.start_link(children, opts) end endCalling FunctionsFacade modules allow you to call Oban functions on instances with custom names (rather than Oban), without passing a Oban.name/0 as the first argument.For example:# Instead of: Oban.config(MyApp.Oban) # You can do: MyApp.Oban.config()Facades also make piping into Oban functions far more convenient:%{some: :args} |> MyWorker.new() |> MyOban.insert()Merging ConfigurationAll configuration can be provided through the use macro or through the application configuration, and options from the application supersedes those passed through use. Configuration is prioritized in this order:Options passed through useOptions pulled from the OTP app specified by :otp_app via Application.get_env/3Options passed through a child spec in the supervisor cancel_all_jobs(name \\ __MODULE__, queryable) (since 2.9.0) @spec cancel_all_jobs(name(), queryable :: Ecto.Queryable.t()) :: {:ok, non_neg_integer()} Cancel many jobs based on a queryable and mark them as cancelled to prevent them from running.Any currently executing jobs are killed. If executing jobs happen to fail before cancellation then the state is set to cancelled. However, any that complete successfully will remain completed.Only jobs with the statuses executing, available, scheduled, or retryable can be cancelled.ExampleCancel all jobs:Oban.cancel_all_jobs(Oban.Job) {:ok, 9}Cancel all jobs for a specific worker:Oban.Job |> Ecto.Query.where(worker: "MyApp.MyWorker") |> Oban.cancel_all_jobs() {:ok, 2} cancel_job(name \\ __MODULE__, job_or_id) (since 1.3.0) @spec cancel_job(name(), job_or_id()) :: :ok Cancel an executing, available, scheduled or retryable job and mark it as cancelled to prevent it from running. If the job is currently executing it will be killed and otherwise it is ignored.If an executing job happens to fail before it can be cancelled the state is set to cancelled. However, if it manages to complete successfully then the state will still be completed.ExampleCancel a job:Oban.cancel_job(job) :okCancel a job for a custom instance:Oban.cancel_job(MyOban, job) :ok check_all_queues(name \\ __MODULE__) @spec check_all_queues(name()) :: [queue_state()] Check the current state of all queue producers.ExampleGet information about all running queues for the default instance:Enum.map(Oban.check_all_queues(), &Map.take(&1, [:queue, :limit])) [%{queue: "default", limit: 10}, %{queue: "other", limit: 5}]Get information for an alternate instance:Oban.check_all_queues(Other.Oban) check_queue(name \\ __MODULE__, opts) (since 2.2.0) @spec check_queue(name(), opts :: [{:queue, queue_name()}]) :: nil | queue_state() Check the current state of a queue producer.This allows you to introspect on a queue's health by retrieving key attributes of the producer's state; values such as the current limit, the running job ids, and when the producer was started.Options:queue - a string or atom specifying the queue to check, requiredExampleGet details about the default queue:Oban.check_queue(queue: :default) %{ limit: 10, node: "me@local", paused: false, queue: "default", running: [100, 102], started_at: ~D[2020-10-07 15:31:00], updated_at: ~D[2020-10-07 15:31:00] }Attempt to get details about a queue that isn't running locally:Oban.check_queue(queue: :not_really_running) nil config(name \\ __MODULE__) (since 0.2.0) @spec config(name()) :: Oban.Config.t() Retrieve the Oban.Config struct for a named Oban supervision tree.ExampleRetrieve the default Oban instance config:%Oban.Config{} = Oban.config()Retrieve the config for an instance started with a custom name:%Oban.Config{} = Oban.config(MyCustomOban) delete_all_jobs(name \\ __MODULE__, queryable) (since 1.19.0) @spec delete_all_jobs(name(), queryable :: Ecto.Queryable.t()) :: {:ok, non_neg_integer()} Delete many jobs based on a queryable.Only jobs that aren't executing may be deleted.ExampleDelete all jobs for a specific worker:Oban.Job |> Ecto.Query.where(worker: "MyApp.MyWorker") |> Oban.delete_all_jobs() {:ok, 9} delete_job(name \\ __MODULE__, job_or_id) (since 1.19.0) @spec delete_job(name(), job_or_id()) :: :ok Delete a job that's not currently executing.ExampleDelete a job:Oban.delete_job(job) :okDelete a job for a custom instance:Oban.delete_job(MyOban, job) :ok drain_queue(name \\ __MODULE__, opts) (since 0.4.0) @spec drain_queue(name(), [drain_option()]) :: drain_result() Synchronously execute all available jobs in a queue.All execution happens within the current process and it is guaranteed not to raise an error or exit.Draining a queue from within the current process is especially useful for testing. Jobs that are enqueued by a process when Ecto is in sandbox mode are only visible to that process. Calling drain_queue/2 allows you to control when the jobs are executed and to wait synchronously for all jobs to complete.Failures & RetriesDraining a queue uses the same execution mechanism as regular job dispatch. That means that any job failures or crashes are captured and result in a retry. Retries are scheduled in the future with backoff and won't be retried immediately.By default jobs are executed in safe mode, just as they are in production. Safe mode catches any errors or exits and records the formatted error in the job's errors array. That means exceptions and crashes are not bubbled up to the calling process.If you expect jobs to fail, would like to track failures, or need to check for specific errors you can pass the with_safety: false flag. See the "Options" section below for more details.Scheduled JobsBy default, drain_queue/2 will execute all currently available jobs. In order to execute scheduled jobs, you may pass the with_scheduled: true which will cause all scheduled jobs to be marked as available beforehand. To run jobs scheduled up to a specific point in time, pass a DateTime instead.Options:queue - a string or atom specifying the queue to drain, required:with_limit — the maximum number of jobs to drain at once. When recursion is enabled this is how many jobs are processed per-iteration.:with_recursion — whether to keep draining a queue repeatedly when jobs insert more jobs:with_safety — whether to silently catch errors when draining, defaults to true. When false, raised exceptions or unhandled exits are reraised (unhandled exits are wrapped in Oban.CrashError).:with_scheduled — whether to include any scheduled jobs when draining, default false. When true, drains all scheduled jobs. When a DateTime is provided, drains all jobs scheduled up to, and including, that point in time.ExampleDrain a queue with three available jobs, two of which succeed and one of which fails:Oban.drain_queue(queue: :default) %{failure: 1, snoozed: 0, success: 2}Drain a queue including any scheduled jobs:Oban.drain_queue(queue: :default, with_scheduled: true) %{failure: 0, snoozed: 0, success: 1}Drain a queue including jobs scheduled up to a minute:Oban.drain_queue(queue: :default, with_scheduled: DateTime.add(DateTime.utc_now(), 60, :second))Drain a queue and assert an error is raised:assert_raise RuntimeError, fn -> Oban.drain_queue(queue: :risky, with_safety: false) endDrain a queue repeatedly until there aren't any more jobs to run. This is particularly useful for testing jobs that enqueue other jobs:Oban.drain_queue(queue: :default, with_recursion: true) %{failure: 1, snoozed: 0, success: 2}Drain only the top (by scheduled time and priority) five jobs off a queue:Oban.drain_queue(queue: :default, with_limit: 5) %{failure: 0, snoozed: 0, success: 1}Drain a queue recursively, only one job at a time:Oban.drain_queue(queue: :default, with_limit: 1, with_recursion: true) %{failure: 0, snoozed: 0, success: 3} insert(name \\ __MODULE__, changeset, opts \\ []) (since 0.7.0) @spec insert(name(), Oban.Job.changeset(), Keyword.t()) :: {:ok, Oban.Job.t()} | {:error, Oban.Job.changeset() | term()} @spec insert(Ecto.Multi.t(), multi_name(), changeset_or_fun()) :: Ecto.Multi.t() Insert a new job into the database for execution.This and the other insert variants are the recommended way to enqueue jobs because they support features like unique jobs.See the section on "Unique Jobs" for more details.ExampleInsert a single job:{:ok, job} = Oban.insert(MyApp.Worker.new(%{id: 1}))Insert a job while ensuring that it is unique within the past 30 seconds:{:ok, job} = Oban.insert(MyApp.Worker.new(%{id: 1}, unique: [period: 30]))Insert a job using a custom timeout:{:ok, job} = Oban.insert(MyApp.Worker.new(%{id: 1}), timeout: 10_000)Insert a job using an alternative instance name:{:ok, job} = Oban.insert(MyOban, MyApp.Worker.new(%{id: 1})) insert(name, multi, multi_name, changeset, opts) (since 0.7.0) @spec insert(name(), Ecto.Multi.t(), multi_name(), changeset_or_fun(), Keyword.t()) :: Ecto.Multi.t() Put a job insert operation into an Ecto.Multi.Like insert/2, this variant is recommended over Ecto.Multi.insert because it supports all of Oban's features, i.e. unique jobs.See the section on "Unique Jobs" for more details.ExampleEcto.Multi.new() |> Oban.insert("job-1", MyApp.Worker.new(%{id: 1})) |> Oban.insert("job-2", fn _ -> MyApp.Worker.new(%{id: 2}) end) |> MyApp.Repo.transaction() insert!(name \\ __MODULE__, changeset, opts \\ []) (since 0.7.0) @spec insert!(name(), Oban.Job.changeset(), opts :: Keyword.t()) :: Oban.Job.t() Similar to insert/3, but raises an Ecto.InvalidChangesetError if the job can't be inserted.ExampleInsert a single job:job = Oban.insert!(MyApp.Worker.new(%{id: 1}))Insert a job using a custom timeout:job = Oban.insert!(MyApp.Worker.new(%{id: 1}), timeout: 10_000)Insert a job using an alternative instance name:job = Oban.insert!(MyOban, MyApp.Worker.new(%{id: 1})) insert_all(name \\ __MODULE__, changesets, opts \\ []) (since 0.9.0) @spec insert_all( name() | Ecto.Multi.t(), changesets_or_wrapper() | multi_name(), Keyword.t() | changesets_or_wrapper_or_fun() ) :: [Oban.Job.t()] | Ecto.Multi.t() Insert multiple jobs into the database for execution.There are a few important differences between this function and Ecto.Repo.insert_all/3:This function always returns a list rather than a tuple of {count, records}This function accepts a list of changesets rather than a list of maps or keyword listsError Handling and RollbacksIf insert_all encounters an issue, the function will raise an error based on your database adapter. This behavior is valuable in conjunction with Ecto.Repo.transaction/2 because it allows for rollbacks.For example, an invalid changeset raises:* (Ecto.InvalidChangesetError) could not perform insert because changeset is invalid.Dolphin Engine and Generated ValuesMySQL doesn't return anything on insertion into the database. That means any values generated by the database, namely the primary key and timestamps, aren't included in the job structs returned from insert_all.🌟 Unique Jobs and BatchingOnly the Smart Engine in Oban Pro supports bulk unique jobs, automatic insert batching, and minimizes parameters sent over the wire. With the basic engine, you must use insert/3 to insert unique jobs one at a time.OptionsAccepts any of Ecto's "Shared Options" such as timeout and log.ExampleInsert a list of 100 jobs at once:1..100 |> Enum.map(&MyApp.Worker.new(%{id: &1})) |> Oban.insert_all()Insert a stream of jobs at once (be sure the stream terminates!):(fn -> MyApp.Worker.new(%{})) |> Stream.repeatedly() |> Stream.take(100) |> Oban.insert_all()Insert with a custom timeout:1..100 |> Enum.map(&MyApp.Worker.new(%{id: &1})) |> Oban.insert_all(timeout: 10_000)Insert with an alternative instance name:changesets = Enum.map(1..100, &MyApp.Worker.new(%{id: &1})) jobs = Oban.insert_all(MyOban, changesets) insert_all(name, multi, multi_name, changesets, opts) (since 0.9.0) @spec insert_all( name(), Ecto.Multi.t(), multi_name(), changesets_or_wrapper_or_fun(), Keyword.t() ) :: Ecto.Multi.t() Put an insert_all operation into an Ecto.Multi.This function supports the same features and has the same caveats as insert_all/2.ExampleInsert job changesets within a multi:changesets = Enum.map(0..100, &MyApp.Worker.new(%{id: &1})) Ecto.Multi.new() |> Oban.insert_all(:jobs, changesets) |> MyApp.Repo.transaction()Insert job changesets using a function:Ecto.Multi.new() |> Ecto.Multi.insert(:user, user_changeset) |> Oban.insert_all(:jobs, fn %{user: user} -> email_job = EmailWorker.new(%{id: user.id}) staff_job = StaffWorker.new(%{id: user.id}) [email_job, staff_job] end) |> MyApp.Repo.transaction() pause_all_queues(name, opts) (since 2.17.0) @spec pause_all_queues(name(), opts :: [queue_all_option()]) :: :ok | {:error, Exception.t()} Pause all running queues to prevent them from executing any new jobs.See pause_queue/2 for options and details.ExamplePause all queues:Oban.pause_all_queues()Pause all queues on the local node:Oban.pause_all_queues(local_only: true)Pause all queues on a specific node:Oban.pause_all_queues(node: "worker.1")Pause all queues for an alternative instance name:Oban.pause_all_queues(MyOban) pause_queue(name \\ __MODULE__, opts) (since 0.2.0) @spec pause_queue(name(), opts :: [queue_option()]) :: :ok | {:error, Exception.t()} Pause a running queue, preventing it from executing any new jobs. All running jobs will remain running until they are finished.When shutdown begins all queues are paused.Options:queue - a string or atom specifying the queue to pause, required:local_only - whether the queue will be paused only on the local node, default: false:node - restrict pausing to a particular nodeNote: by default, Oban does not verify that the given queue exists unless :local_only is set to true as even if the queue does not exist locally, it might be running on another node.ExamplePause the default queue:Oban.pause_queue(queue: :default) :okPause the default queue, but only on the local node:Oban.pause_queue(queue: :default, local_only: true) :okPause the default queue only on a particular node:Oban.pause_queue(queue: :default, node: "worker.1") :ok resume_all_queues(name, opts) (since 2.17.0) @spec resume_all_queues(name(), opts :: [queue_all_option()]) :: :ok | {:error, Exception.t()} Resume executing jobs in all paused queues.See resume_queue/2 for options and details.ExampleResume all queues:Oban.resume_all_queues()Resume all queues on the local node:Oban.resume_all_queues(local_only: true)Resume all queues on a specific node:Oban.resume_all_queues(node: "worker.1")Resume all queues for an alternative instance name:Oban.resume_all_queues(MyOban) resume_queue(name \\ __MODULE__, opts) (since 0.2.0) @spec resume_queue(name(), opts :: [queue_option()]) :: :ok | {:error, Exception.t()} Resume executing jobs in a paused queue.Options:queue - a string or atom specifying the queue to resume, required:local_only - whether the queue will be resumed only on the local node, default: false:node - restrict resuming to a particular nodeNote: by default, Oban does not verify that the given queue exists unless :local_only is set to true as even if the queue does not exist locally, it might be running on another node.ExampleResume a paused default queue:Oban.resume_queue(queue: :default)Resume the default queue, but only on the local node:Oban.resume_queue(queue: :default, local_only: true)Resume the default queue only on a particular node:Oban.resume_queue(queue: :default, node: "worker.1") retry_all_jobs(name \\ __MODULE__, queryable) (since 2.9.0) @spec retry_all_jobs(name(), queryable :: Ecto.Queryable.t()) :: {:ok, non_neg_integer()} Retries all jobs that match on the given queryable.If no queryable is given, Oban will retry all jobs that aren't currently available or executing. Note that regardless of constraints, it will never retry available or executing jobs.ExampleRetries jobs in any state other than available or executing:Oban.retry_all_jobs(Oban.Job) {:ok, 9}Retries jobs with the retryable state:Oban.Job |> Ecto.Query.where(state: "retryable") |> Oban.retry_all_jobs() {:ok, 3}Retries all inactive jobs with priority 0Oban.Job |> Ecto.Query.where(priority: 0) |> Oban.retry_all_jobs() {:ok, 5} retry_job(name \\ __MODULE__, job_or_id) (since 2.2.0) @spec retry_job(name(), job_or_id()) :: :ok Sets a job as available, adding attempts if already maxed out. Jobs currently available or executing are ignored. The job is scheduled for immediate execution.ExampleRetry a job:Oban.retry_job(job) :ok scale_queue(name \\ __MODULE__, opts) (since 0.2.0) @spec scale_queue(name(), opts :: [queue_option() | {:limit, pos_integer()}]) :: :ok | {:error, Exception.t()} Scale the concurrency for a queue.Options:queue - a string or atom specifying the queue to scale, required:limit — the new concurrency limit, required:local_only — whether the queue will be scaled only on the local node, default: false:node - restrict scaling to a particular nodeIn addition, all engine-specific queue options are passed along after validation.Note: by default, Oban does not verify that the given queue exists unless :local_only is set to true as even if the queue does not exist locally, it might be running on another node.ExampleScale a queue up, triggering immediate execution of queued jobs:Oban.scale_queue(queue: :default, limit: 50) :okScale the queue back down, allowing executing jobs to finish:Oban.scale_queue(queue: :default, limit: 5) :okScale the queue only on the local node:Oban.scale_queue(queue: :default, limit: 10, local_only: true) :okScale the queue on a particular node:Oban.scale_queue(queue: :default, limit: 10, node: "worker.1") :ok start_link(opts) (since 0.1.0) @spec start_link([option()]) :: Supervisor.on_start() Starts an Oban supervision tree linked to the current process.OptionsThese options are required; without them the supervisor won't start::repo — specifies the Ecto repo used to insert and retrieve jobsPrimary OptionsThese options determine what the system does at a high level, i.e. which queues to run::engine — facilitates inserting, fetching, and otherwise managing jobs.There are three built-in engines: Oban.Engines.Basic for Postgres databases, Oban.Engines.Lite for SQLite3 databases, and Oban.Engines.Inline for simplified testing (only available for :inline testing mode).When the Oban.Engines.Lite engine is used the :notifier and :peer are automatically set to PG and isolated mode, respectively.Additional engines, such as Oban Pro's SmartEngine with advanced functionality for Postgres, are also available as an add-on.Defaults to the Basic engine for Postgres.:log — either false to disable logging or a standard log level (:error, :warning, :info, :debug, etc.). This determines whether queries are logged or not; overriding the repo's configured log level. Defaults to false, where no queries are logged.:name — used for supervisor registration, it must be unique across an entire VM instance. Defaults to Oban when no name is provided.:node — used to identify the node that the supervision tree is running in. If no value is provided it will use the node name in a distributed system, or the hostname in an isolated node. See "Node Name" below.:notifier — used to relay messages between processes, nodes, and the Postgres database.There are two built-in notifiers: Oban.Notifiers.Postgres, which uses Postgres PubSub; and Oban.Notifiers.PG, which uses process groups with distributed erlang. Defaults to the Postgres notifier.:peer — used to specify which peer module to use for cluster leadership.There are two built-in peers: Oban.Peers.Database, which uses table-based leadership through the oban_peers table; and Oban.Peers.Global, which uses global locks through distributed Erlang.Leadership can be disabled by setting peer: false, but note that centralized plugins like Cron won't run without leadership.Defaults to the Database peer.:plugins — a list or modules or module/option tuples that are started as children of an Oban supervisor. Any supervisable module is a valid plugin, i.e. a GenServer or an Agent. May also be set to false to disable plugins and disable leadership.:prefix — the query prefix, or schema, to use for inserting and executing jobs. An oban_jobs table must exist within the prefix. See the "Prefix Support" section in the module documentation for more details.:queues — a keyword list where the keys are queue names and the values are the concurrency setting or a keyword list of queue options. For example, setting queues to [default: 10, exports: 5] would start the queues default and exports with a combined concurrency level of 15. The concurrency setting specifies how many jobs each queue will run concurrently.Queues accept additional override options to customize their behavior, e.g. by setting paused or dispatch_cooldown for a specific queue.Using an empty list or false prevents any queues from starting on init.:testing — a mode that controls how an instance is configured for testing. When set to :inline or :manual queues, peers, and plugins are automatically disabled. Defaults to :disabled, no test mode.Twiddly OptionsAdditional options used to tune system behaviour. These are primarily useful for testing or troubleshooting and don't usually need modification.:dispatch_cooldown — the minimum number of milliseconds a producer will wait before fetching and running more jobs. A slight cooldown period prevents a producer from flooding with messages and thrashing the database. The cooldown period directly impacts a producer's throughput: jobs per second for a single queue is calculated by (1000 / cooldown) * limit. For example, with a 5ms cooldown and a queue limit of 25 a single queue can run 5,000 jobs/sec.The default is 5ms and the minimum is 1ms, which is likely faster than the database can return new jobs to run.:insert_trigger — whether to dispatch notifications to relevant queues as jobs are inserted into the database. At high load, e.g. thousands or more job inserts per second, notifications may become a bottleneck.The trigger mechanism is designed to make jobs execute immediately after insert, rather than up to :stage_interval (1 second) afterwards, and it can safely be disabled to improve insert throughput.Defaults to true, with triggering enabled.:shutdown_grace_period — the amount of time a queue will wait for executing jobs to complete before hard shutdown, specified in milliseconds. The default is 15_000, or 15 seconds.:stage_interval — the number of milliseconds between making scheduled jobs available and notifying relevant queues that jobs are available. This is directly tied to the resolution of scheduled or retryable jobs and how frequently the database is checked for jobs to run. To minimize database load, only 5_000 jobs are staged at each interval.Only the leader node stages jobs and notifies queues when the :notifier's pubsub notifications are functional. If pubsub messages can't get through then staging switches to a less efficient "local" mode in which all nodes poll for jobs to run.Setting the interval to :infinity disables staging entirely. The default is 1_000ms.ExampleStart a stand-alone Oban instance:{:ok, pid} = Oban.start_link(repo: MyApp.Repo, queues: [default: 10])To start an Oban instance within an application's supervision tree:def start(_type, _args) do children = [MyApp.Repo, {Oban, repo: MyApp.Repo, queues: [default: 10]}] Supervisor.start_link(children, strategy: :one_for_one, name: MyApp.Supervisor) endStart multiple, named Oban supervisors within a supervision tree: children = [ MyApp.Repo, {Oban, name: Oban.A, repo: MyApp.Repo, queues: [default: 10]}, {Oban, name: Oban.B, repo: MyApp.Repo, queues: [special: 10]}, ] Supervisor.start_link(children, strategy: :one_for_one, name: MyApp.Supervisor)Start a local Oban instance for SQLite:{:ok, pid} = Oban.start_link(engine: Oban.Engines.Lite, repo: MyApp.Repo)Node NameWhen the node value has not been configured it is generated based on the environment:If the local node is alive (e.g. in a distributed system, or when running from a mix release) the node name is usedIn a Heroku environment the system environment's DYNO value is usedOtherwise, the system hostname is usedWhen running a mix release on a Heroku node, the node is alive even if not part of a distributed system. In order to use the DYNO value, configure the node value using runtime configuration via config/runtime.exs: config :my_app, Oban, node: System.get_env("DYNO", "nonode@nohost") start_queue(name \\ __MODULE__, opts) (since 0.12.0) @spec start_queue(name(), opts :: Keyword.t()) :: :ok | {:error, Exception.t()} Start a new supervised queue.By default this starts a new supervised queue across all nodes running Oban on the same database and prefix. You can pass the option local_only: true if you prefer to start the queue only on the local node.Options:queue - a string or atom specifying the queue to start, required:local_only - whether the queue will be started only on the local node, default: false:limit - set the concurrency limit, required:paused — set whether the queue starts in the "paused" state, optionalIn addition, all engine-specific queue options are passed along after validation.ExampleStart the :priority queue with a concurrency limit of 10 across the connected nodes.Oban.start_queue(queue: :priority, limit: 10) :okStart the :media queue with a concurrency limit of 5 only on the local node.Oban.start_queue(queue: :media, limit: 5, local_only: true) :okStart the :media queue on a particular node.Oban.start_queue(queue: :media, limit: 5, node: "worker.1") :okStart the :media queue in a paused state.Oban.start_queue(queue: :media, limit: 5, paused: true) :ok stop_queue(name \\ __MODULE__, opts) (since 0.12.0) @spec stop_queue(name(), opts :: [queue_option()]) :: :ok | {:error, Exception.t()} Shutdown a queue's supervision tree and stop running jobs for that queue.By default this action will occur across all the running nodes. Still, if you prefer to stop the queue's supervision tree and stop running jobs for that queue only on the local node, you can pass the option: local_only: trueThe shutdown process pauses the queue first and allows current jobs to exit gracefully, provided they finish within the shutdown limit.Note: by default, Oban does not verify that the given queue exists unless :local_only is set to true as even if the queue does not exist locally, it might be running on another node.Options:queue - a string or atom specifying the queue to stop, required:local_only - whether the queue will be stopped only on the local node, default: false:node - restrict stopping to a particular nodeExampleStop a running queue on all nodes:Oban.stop_queue(queue: :default) :okStop the queue only on the local node:Oban.stop_queue(queue: :media, local_only: true) :okStop the queue only on a particular node:Oban.stop_queue(queue: :media, node: "worker.1") :ok update_job(name \\ __MODULE__, job_or_id, changes_or_fun) (since 2.20.0) @spec update_job(name(), job_or_id(), map() | (Oban.Job.t() -> map())) :: {:ok, Oban.Job.t()} | {:error, term()} Update a job with the given changes.This function accepts either a job struct or id, along with either a map of changes or a function that receives the job and returns a map of changes.The update operation is wrapped in a transaction with a locking clause (when available) to prevent concurrent modifications.Fields and ValidationsAll changes are validated using the same validations as insert/2. Only the following subset of fields can be updated::args:max_attempts:meta:priority:queue:scheduled_at:tags:workerUpdating Executing JobsUse caution when updating jobs that are currently executing. Modifying fields like :args, :queue, or :worker while a job is running may lead to unexpected behavior or inconsistent state. Consider whether the job should be cancelled first, or if the update should be deferred until after execution completes.ExamplesUpdate a job with a map of changes:Oban.update_job(job, %{tags: ["urgent"], priority: 0})Update a job by id:Oban.update_job(123, %{tags: ["processed"], meta: %{batch_id: 456}})Update a job using a function:Oban.update_job(job, fn job -> %{tags: ["retry" | job.tags]} end)Using a named Oban instance:Oban.update_job(MyApp.Oban, job, fn job -> %{meta: Map.put(job.meta, "processed_at", DateTime.utc_now())} end) whereis(name) (since 2.2.0) @spec whereis(name()) :: pid() | {atom(), node()} | nil Returns the pid of the root Oban process for the given name.ExampleFind the default instance:Oban.whereis(Oban)Find a dynamically named instance:Oban.whereis({:oban, 1})

```
Oban
```

**Pattern 2:** For example:

```
# Instead of:
Oban.config(MyApp.Oban)

# You can do:
MyApp.Oban.config()
```

**Pattern 3:** Defining Queues View Source Queues are the foundation of how Oban organizes and processes jobs. They allow you to:Separate different types of work (e.g., emails, report generation, media processing)Control the concurrency of job executionPrioritize certain jobs over othersManage resource consumption across your applicationEach queue operates independently with its own set of worker processes and concurrency limits.Basic Queue ConfigurationQueues are defined as a keyword list where the key is the name of the queue and the value is the maximum number of concurrent jobs. The following configuration would start four queues with concurrency ranging from 5 to 50:config :my_app, Oban, queues: [default: 10, mailers: 20, events: 50, media: 5], repo: MyApp.RepoIn this example:The default queue will process up to 10 jobs simultaneouslyThe mailers queue will process up to 20 jobs simultaneouslyThe events queue will process up to 50 jobs simultaneouslyThe media queue will process up to 5 jobs simultaneouslyAdvanced Queue ConfigurationFor more control, you can use an expanded form to configure queues with individual overrides:config :my_app, Oban, queues: [ default: 10, mailers: [limit: 20, dispatch_cooldown: 50], events: [limit: 50, paused: true], media: [limit: 1, global_limit: 10] ], repo: MyApp.RepoThis expanded configuration demonstrates several advanced options:The mailers queue has a dispatch cooldown of 50ms between job fetchingThe events queue starts in a paused state, which means it won't process anything until Oban.resume_queue/2 is called to start itThe media queue uses a global limit (an Oban Pro feature)Paused QueuesWhen a queue is configured with paused: true, it won't process any jobs until explicitly started. This is useful for:Maintenance periodsControlling when resource-intensive jobs can runTemporarily disabling certain types of jobsYou can resume a paused queue programmatically:Oban.resume_queue(queue: :events)And pause an active queue:Oban.pause_queue(queue: :media)Queue Planning GuidelinesThere isn't a limit to the number of queues or how many jobs may execute concurrently in each queue. However, consider these important guidelines:Resource ConsiderationsEach queue will run as many jobs as possible concurrently, up to the configured limit. Make sure your system has enough resources (such as database connections) to handle the concurrent load.Consider the total concurrency across all queues. For example, if you have 4 queues with limits of 10, 20, 30, and 40, your system needs to handle up to 100 concurrent jobs, each potentially requiring database connections and other resources.Concurrency and DistributionQueue limits are local (per-node), not global (per-cluster). For example, running a queue with a local limit of 2 on three separate nodes is effectively a global limit of six concurrent jobs. If you require a global limit, you must restrict the number of nodes running a particular queue or consider Oban Pro's Smart Engine, which can manage global concurrency automatically!Queue PlanningOnly jobs in the configured queues will execute. Jobs in any other queue will stay in the database untouched. Be sure to configure all queues you intend to use.Organize queues by workload characteristics. For example:CPU-intensive jobs might benefit from a dedicated low-concurrency queueI/O-bound jobs (like sending emails) can often use higher concurrencyPriority work should have dedicated queues with higher concurrencyExternal Process ConsiderationsPay attention to the number of concurrent jobs making expensive system calls (such as calls to resource-intensive tools like FFMpeg or ImageMagick). The BEAM ensures that the system stays responsive under load, but those guarantees don't apply when using ports or shelling out commands.Consider creating dedicated queues with lower concurrency for jobs that interact with external processes or services that have their own concurrency limitations.

```
config :my_app, Oban,
  queues: [default: 10, mailers: 20, events: 50, media: 5],
  repo: MyApp.Repo
```

**Pattern 4:** In this example:

```
default
```

**Pattern 5:** Unique Jobs View Source The uniqueness of a job is a somewhat complex topic. This guide is here to help you understand its complexities!The unique jobs feature allows you to specify constraints to prevent enqueuing duplicate jobs. These constraints only apply when jobs are inserted. Uniqueness has no bearing on whether jobs are executed concurrently. Uniqueness is based on a combination of job attributes based on the following options::period — The number of seconds until a job is no longer considered duplicate. You should always specify a period, otherwise Oban will default to 60 seconds. :infinity can be used to indicate the job be considered a duplicate as long as jobs are retained (see Oban.Plugins.Pruner).:fields — The fields to compare when evaluating uniqueness. The available fields are :args, :queue, :worker, and :meta. :fields defaults to [:worker, :queue, :args]. It's recommended that you leave the default :fields, otherwise you risk unexpected conflicts between unrelated jobs.:keys — A specific subset of the :args or :meta to consider when comparing against historic jobs. This allows a job with multiple key/value pairs in its arguments to be compared using only a subset of them.:states — The job states that are checked for duplicates. You can use a named group or a list of individual states. The available named groups are::all - All states:incomplete - Jobs that haven't completed processing:scheduled - Only scheduled jobs (useful for "debouncing"):successful - Jobs that aren't cancelled or discarded (the default)By default, :successful is used, which prevents duplicates even if the previous job has been completed.:timestamp — Which job timestamp to check the period against. The available timestamps are :inserted_at or :scheduled_at. Defaults to :inserted_at for legacy reasons.The simplest form of uniqueness will configure uniqueness for as long as a matching job exists in the database, regardless of state:use Oban.Worker, unique: trueHere's a more complex example which uses multiple options:use Oban.Worker, unique: [ # Jobs should be unique for 2 minutes... period: {2, :minutes}, # ...after being scheduled, not inserted timestamp: :scheduled_at, # Don't consider the whole :args field, but just the :url field within :args keys: [:url], # Consider a job unique across all states, including :cancelled/:discarded states: :all, # Consider a job unique across queues; only compare the :worker and :url key within # the :args, as per the :keys configuration above fields: [:worker, :args] ]Unique GuaranteesOban strives for uniqueness of jobs through transactional locks and database queries. Uniqueness does not rely on unique constraints in the database, which leaves it prone to race conditions in some circumstances.🌟 Pro's Smart Engine does rely on unique constraints and provides strong uniqueness guarantees.Uniqueness vs ConcurrencyUnderstanding the distinction between uniqueness and concurrency is crucial for designing efficient processing pipelines. While these concepts may seem related, they operate at different stages of a job's lifecycle.Uniqueness operates at job insertion time. When a job is marked as unique, Oban checks whether an identical job already exists in the queue before inserting a new one.When it applies-During job insertionWhat it prevents-Duplicate jobs from being insertedWhat it doesn't affect-Which jobs run concurrentlyA common misunderstanding is that unique jobs run one at a time or in sequence. This isn't true—uniqueness only prevents duplicate insertions. Once unique jobs are in the queue, they'll run according to the queue's concurrency settings.For example, given the following configuration that allows 10 concurrent email jobs:config :my_app, Oban, queues: [emails: 10]These 10 unique jobs will all run concurrently:1..10 |> Enum.map(&MyApp.EmailWorker.new(%{user_id: &1}, unique: true)) |> Oban.insert_all()To restrict the number of jobs that run at once you must set concurrency accordingly.Detecting ConflictsWhen unique settings match an existing job, the return value of Oban.insert/2 is still {:ok, job}. However, you can detect a unique conflict by checking the job's :conflict? field. If there was an existing job, the field is true; otherwise it is false.You can use the :conflict? field to customize responses after insert:case Oban.insert(changeset) do {:ok, %Job{id: nil, conflict?: true}} -> {:error, :failed_to_acquire_lock} {:ok, %Job{conflict?: true}} -> {:error, :job_already_exists} result -> result endReplacing ValuesIn addition to detecting unique conflicts, passing options to :replace can update any job field when there is a conflict. Any of the following fields can be replaced per state::args:max_attempts:meta:priority:queue:scheduled_at:tags:workerFor example, to change the :priority and increase :max_attempts when there is a conflict with a job in a :scheduled state:BusinessWorker.new( args, max_attempts: 5, priority: 0, replace: [scheduled: [:max_attempts, :priority]] )Another example is bumping the scheduled time on conflict. Either :scheduled_at or :schedule_in values will work, but the replace option is always :scheduled_at.UrgentWorker.new(args, schedule_in: 1, replace: [scheduled: [:scheduled_at]])Jobs in the :executing StateIf you use this feature to replace a field (such as :args) in the :executing state by doing something likeUniqueWorker.new(new_args, replace: [executing: [:args]])then Oban will update :args, but the job will continue executing with the original value.Specifying Fields and KeysThe :fields option determines which high-level job attributes Oban will consider when checking for uniqueness, including :args, :queue, :worker, and :meta.When :args or :meta are included in the :fields list, the :keys option provides additional specificity by allowing you to designate particular keys within the map for comparison, rather than comparing the entire args map.Let's see this with an example:# This compares the entire args map use Oban.Worker, unique: [fields: [:worker, :queue, :args]] # This compares only the :url key within the args map use Oban.Worker, unique: [keys: [:url], fields: [:worker, :queue, :args]]In the second example, the uniqueness check only looks at the :url key within the :args map because :keys is specified.

```
:period
```

**Pattern 6:** Let's see this with an example:

```
# This compares the entire args map
use Oban.Worker,
  unique: [fields: [:worker, :queue, :args]]

# This compares only the :url key within the args map
use Oban.Worker,
  unique: [keys: [:url], fields: [:worker, :queue, :args]]
```

**Pattern 7:** Reliable Scheduled Jobs View Source A common variant of recursive jobs are "scheduled jobs", where the goal is for a job to repeat indefinitely with a fixed amount of time between executions. The part that makes it "reliable" is the guarantee that we'll keep retrying the job's business logic when the job retries, but we'll only schedule the next occurrence once. In order to achieve this guarantee we'll make use of the perform function to receive a complete Oban.Job struct.Time for illustrative example!Use Case: Delivering Daily Digest EmailsWhen a new user signs up to use our site we need to start sending them daily digest emails. We want to deliver the emails around the same time a user signed up, repeating every 24 hours. It is important that we don't spam them with duplicate emails, so we ensure that the next email is only scheduled on our first attempt.defmodule MyApp.Workers.ScheduledWorker do use Oban.Worker, queue: :scheduled, max_attempts: 10 alias MyApp.Mailer @one_day 60 * 60 * 24 @impl true def perform(%{args: %{"email" => email} = args, attempt: 1}) do args |> new(schedule_in: @one_day) |> Oban.insert!() Mailer.deliver_email(email) end def perform(%{args: %{"email" => email}}) do Mailer.deliver_email(email) end endYou'll notice that the first perform/1 clause only matches a job struct on the first attempt. When it matches, the first clause schedules the next iteration immediately, before attempting to deliver the email. Any subsequent retries fall through to the second perform/1 clause, which only attempts to deliver the email again. Combined, the clauses get us close to at-most-once semantics for scheduling, and at-least-once semantics for delivery.More Flexible Than CRON SchedulingDelivering around the same time using cron-style scheduling would need extra book-keeping to check when a user signed up, and then only deliver to those users that signed up within that window of time. The recursive scheduling approach is more accurate and entirely self contained—when and if the digest interval changes the scheduling will pick it up automatically once our code deploys.An extensive discussion on the Oban issue tracker prompted this example along with the underlying feature that made it possible.Considerations for Scheduling Jobs in the Very-Near-FutureIf you use the schedule_in or scheduled_at options with a value that will resolve to the very-near-future, for example:# 1 second from now %{} |> new(schedule_in: 1) |> Oban.insert() # 500 milliseconds from now very_soon = DateTime.utc_now() |> DateTime.add(500, :millisecond) %{} |> new(scheduled_at: very_soon) |> Oban.insert()your workers may not be aware of/attempt to perform the job until the next tick as specified by the :stage_interval configuration option. By default this is set to 1_000ms.Be aware: Configuring the :stage_interval option below the recommended default can have a considerable impact on database performance! It is not advised to lower this value and should only be done as a last resort after considering other ways to achieve your desired outcome.

```
perform
```

**Pattern 8:** If you use the schedule_in or scheduled_at options with a value that will resolve to the very-near-future, for example:

```
schedule_in
```

### Example Code Patterns

**Example 1** (javascript):
```javascript
defmodule MyApp.MailerWorker do
  use Oban.Worker, queue: :mailers

  @impl Oban.Worker
  def perform(%Oban.Job{args: %{"email" => email} = _args}) do
    _ = Email.deliver(email)
    :ok
  end
end
```

**Example 2** (python):
```python
defmodule MyApp.Workers.Basic do
  use Oban.Worker

  @impl Oban.Worker
  def perform(%Oban.Job{args: args}) do
    IO.inspect(args)
    :ok
  end
end
```

**Example 3** (javascript):
```javascript
Oban.Peer.leader?()
# => true
```

**Example 4** (python):
```python
defprotocol MyApp.Reportable do
  @fallback_to_any true
  def reportable?(worker, attempt)
end

defimpl MyApp.Reportable, for: Any do
  def reportable?(_worker, _attempt), do: true
end
```

## Reference Files

This skill includes comprehensive documentation in `references/`:

- **configuration.md** - Configuration documentation
- **getting_started.md** - Getting Started documentation
- **other.md** - Other documentation
- **plugins.md** - Plugins documentation
- **queues.md** - Queues documentation
- **testing.md** - Testing documentation
- **troubleshooting.md** - Troubleshooting documentation
- **workers.md** - Workers documentation

Use `view` to read specific reference files when detailed information is needed.

## Working with This Skill

### For Beginners
Start with the getting_started or tutorials reference files for foundational concepts.

### For Specific Features
Use the appropriate category reference file (api, guides, etc.) for detailed information.

### For Code Examples
The quick reference section above contains common patterns extracted from the official docs.

## Resources

### references/
Organized documentation extracted from official sources. These files contain:
- Detailed explanations
- Code examples with language annotations
- Links to original documentation
- Table of contents for quick navigation

### scripts/
Add helper scripts here for common automation tasks.

### assets/
Add templates, boilerplate, or example projects here.

## Notes

- This skill was automatically generated from official documentation
- Reference files preserve the structure and examples from source docs
- Code examples include language detection for better syntax highlighting
- Quick reference patterns are extracted from common usage examples in the docs

## Updating

To refresh this skill with updated documentation:
1. Re-run the scraper with the same configuration
2. The skill will be rebuilt with the latest information
